# Word Vectors in the Eighteenth Century, Episode 3: From Fields to Vectors

## 0. Introduction

Where to begin? The question can be daunting. With hundreds of thousands of word vectors, each of which related to every other in different ways and degrees, how does one first enter, as it were, into the matrix?

A natural and grounding place for me to begin was by turning to [previous work on DH semantics](http://litlab.stanford.edu/LiteraryLabPamphlet4.pdf) that [Long Le-Khac](https://english.artsci.wustl.edu/people/long-le-khac) and I did a few years ago. We designed a tool, *Correlator*, to find words whose historical frequency trajectory was similar to a target word: "virtue" as a seed word yielded words like "integrity", "modesty", and "sensibility". At the time, we were shocked that historical frequency correlation provided a rough approximation of semantic similarity. To build semantic *fields*, we subcategorized Correlator's lists and then expanded them using synonyms drawn from the OED's Historical Thesaurus. To transform semantic fields into semantic *cohorts*, we excluded words in each field that followed a historical trajectory especially deviant from the dominant trajectory of the group.

<small>[Looking back, Correlator seems similar to VSMs to me, in its shared aim of finding related words to a target word. VSMs also make this possible: we can easily ask, which word X is closest to word Y in the vector space? But Correlator proximity in VSMs is calculated along 50-500 dimensions that were built from micro-textual contexts of 5 words long. In Correlator, proximity is calculated only along 10 dimensions, corresponding to the normalized counts of the word in each of the ten decades of the nineteenth century.]</small>

In any case, this process yielded two dominant groups of semantic fields: one falling in the nineteenth-century novel, and one rising.

  1. Abstract Values (*Falling in frequency through 19C; rising for most of 18C*)
	-	Moral Valuation
		*	character, honour, conduct, respect, worthy, temper, innocent, ...
	-	Social Restraint
		*	gentle, pride, proud, proper, agreeable, humble, sensible, ...
	-	Sentiment
		*	heart, feeling, passion, bosom, emotion, sentiment, ardent, ...
	-	Partiality
		*	correct, prejudice, partial, disinterested, partiality, prejudiced, detached, ...
  2. Hard Seed (*Rising through 19C; falling for most of 18C*)
	-	Action Verbs
		*	see, come, go, came, look, let, looked, ...
	-	Body Parts
		*	eyes, hand, face, head, hands, eye, arms, ...
	-	Physical Adjectives
		*	round, hard, low, clear, heavy, hot, straight, ...
	-	Colors
		*	white, black, red, blue, green, gold, grey, ...
	-	Locative Prepositions
		*	out, up, over, down, away, back, through, ...
	-	Numbers
		*	two, three, ten, thousand, four, five, hundred, ...

But how can we move from this *field/cohort* model of semantics, where relatedness is a product of both historical correlation and thesaurus-based synonymy, to a *spatial* model of semantics where relatedness is expressed along the hidden dimensions of the vector space model?


## 1. Semantic fields in vector space

One simple experiment would be to ask, for each word in any of the above semantic cohorts, which three other words already in one of the semantic cohorts are *closest* to it in the vector space? These relationships (each word to its three closest neighbors) can then be visualized as a network, coloring nodes (the 881 words from all semantic cohorts) by their cohort assignment:

<center><a href="/assets/semfield-graph.png" target="_blank"><img src="/assets/semfield-graph.png" alt="Fruchterman Reingold" width=250 alt="Figure 10: Network of all words in the "Hard Seed" and "Abstract Values" semantic fields, each connected to the three words closest to it in the vector space. In this figure, the top three closest words are restricted to those words already in one of the semantic fields. 881 words/nodes; 2,009 edges. Fruchterman Reingold layout."></a> <img src="/assets/semfield-key.png" alt="A geometric proof by Aristotle" width=250 alt="Figure 10: Network of all words in the "Hard Seed" and "Abstract Values" semantic fields, each connected to the three words closest to it in the vector space. In this figure, the top three closest words are restricted to those words already in one of the semantic fields. 881 words/nodes; 2,009 edges. Fruchterman Reingold layout."></center>
*<small>Figure 10: Network of all words in the "Hard Seed" and "Abstract Values" semantic fields, each connected to the three words closest to it in the vector space. In this figure, the top three closest words are restricted to those words already in one of the semantic fields. 881 words/nodes; 2,009 edges. Fruchterman Reingold layout. [Interactive version here](http://ryanheuser.org/gexf/semanticfields.html).</small>*

Right away one notices that the semantic classification of these words into fields/cohorts is to a large extent preserved in the vector space model. When we build a network between the words based on their distances to each other in the model, words tend to be closer to words within their own semantic field. This asymmetry produces regions of the network largely occupied by a particular field: Action Verbs in pink, Body Parts in blue, Colors in orange, Numbers in turquoise—they all both occupy their own region, and at the same time, together they constitute a western and southern hemisphere given over to the semantics of concreteness.

The abstract fields are less tightly bound, with Social Restraint and Moral Valuation in green and grey stretched together across the northeast, intermixing also with the Sentiment (in red) field. On [closer inspection](http://ryanheuser.org/gexf/semanticfields.html), however, it's clear that the model has rearranged the abstract semantic fields according to its own semantic organization. The northern words in the abstract fields are *positively* valued (moderation, reputation, admiration) and the south-eastern words (indecent, unseemly, inconsiderate) are *negatively* valued. The intermixed Sentiment field has also been split across this positive-negative dimension, as well as connected to concrete terms (e.g. "tearless" [Sentiment] to "quivered" [Action Verb]). Another cause of reorganization is grammatical: adverbs, adjectives, and nouns are all more likely to connect to each other.

But what happens when we allow these 881 words to connect to their closest word-vectors, this time allowing them to connect to *any* word in the model? I've also allowed any word brought into the network that was not part of the original 881 words, to itself connect to its own three closest words, whatever they are. What results is the vector space equivalent of Correlator's finding more related words. Spinning off the metaphor of the neural network, if the vector space model is a single abstract representation of 18C semantics, then we can also think of it as a kind of abstracted, quasi-Lockean eighteenth-century "Mind": a virtual form, too, perhaps, of Sterne's "great SENSORIUM of the world!" If so, one can almost imagine such a Mind perceiving the semantic fields in Figure 10, and then activating them within its own mental map of their proximal semantics—a map that has an order of magnitude more words:

<center><a href="/assets/semfield-expanded-graph2.png" target="_blank"><img src="/assets/semfield-expanded-graph2.png" alt="Fruchterman Reingold" width=250 alt="Figure 11: Network of all words in the "Hard Seed" and "Abstract Values" semantic fields, each connected to the three words closest to it in the vector space. In this figure, the top three closest words are NOT restricted to those words already in one of the semantic fields. 4,914 words/nodes; 6,126 edges. Fruchterman Reingold layout."></a> <img src="/assets/semfield-expanded-key2.png" alt="A geometric proof by Aristotle" width=250 alt="Figure 11: Network of all words in the "Hard Seed" and "Abstract Values" semantic fields, each connected to the three words closest to it in the vector space. In this figure, the top three closest words are NOT restricted to those words already in one of the semantic fields. 4,914 words/nodes; 6,126 edges. Fruchterman Reingold layout."></center>
*<small>Figure 11: Similar to Figure 10, except the top three closest words are <u>not</u> restricted to those words already in one of the semantic fields. 4,914 words/nodes; 6,126 edges. Fruchterman Reingold layout. [Interactive version here](http://ryanheuser.org/gexf/semanticfields-expanded.html).</small>*

Here the semantic fields are still somewhat self-connected; but they're also more disconnected, related still more distantly within a wider representation of their nearby semantics. [Looking more closely](http://ryanheuser.org/gexf/semanticfields-expanded.html), we can see that a still more complex semantic reorganizations has taken place. In the northwest quadrant, there's one cluster of Moral Valuation and Social Restraint words that cross the positive-negative value polarity, but which are connected by their shared semantics of more religiously-inflected ethics (virtue, vice, sin, iniquity, pride, vanity). And to the northwest of *it*, there's also another group of Moral Valuation and Social Restraint words that have a more socially-inflected ethics relating to manners (honour, goodness, politeness, courtesy, civility). Although this is the semantic distinction that Long and I tried to capture in the Moral Valuation and Social Restraint fields, the vector space model has reconfigured our fields—to some extent suggesting that, at least for the 18C as seen through ECCO-TCP, we may have gotten them a little wrong. Further complicating the graph's reorganization is the fact that almost the whole western hemisphere is made up of nouns, the north-eastern quadrant adjectives, and the south-eastern quadrant verbs.


### Discussion: Fields and vectors

I think this experiment shows that vector space semantics can replicate some of the semantic organization that Long and I constructed from a combination of supervised and unsupervised methods. But it also shows the ways in which vector space semantics is, by definition, a more multidimensional approach to semantics than correlation by historical frequency. This is not at all a critique of the semantic cohort method: semantic *cohorts*, groups of words that rise and fall together in the history of a genre or discourse, have the conceptual advantage of producing a sharply historically-determined semantic entity for interpretation.

But it *is* an attempt to articulate, through contrast, what is unique about semantics in a vector space. As we've seen from the networks, semantic proximity/similarity is a tricky concept. Is "virtue" similar to "virtuous"? Well, yes—both words of the same root, etc. But also, no—one is an adjective, the other a noun. The vector space model represents both this similarity and this difference through its multidimensionality: on certain dimensions and vectors, they're close together; on others, they're far apart. If we wanted to exclude the semantic profile of virtuous-as-adjective, we could have referenced not V(virtuous), but V(virtuous)-V([all adjectives]). But this kind of representation, not virtous-ness but virtuous-ness-*as-distinct-from-adjective-ness*, makes it all the more clear that multidimensional semantic models require, on the part of the researcher, multidimensional approaches to semantic questions—to think with and not against the matrix—in order to render its multidimensionality into a feature, and not a bug.



## 2. Vectors of abstraction

Building on [Experiment 1](#semanticfields) on semantic fields/cohorts—a useful but very different approach to semantics from vector space models—how can we move toward an experimental design that thinks more natively within the multidimensionality of a vector space?

One way to do so would be to reapproach the primary semantic contrast expressed by the difference between the Abstract Values semantic field (with words like virtue, modesty, integrity, sensibility, ...) and the Hard Seed field (hard, come, go, red, blue, arm, ...). [See [Experiment 1](#semanticfields) for more details.] That primary contrast would seem to be the contrast between abstract and concrete discourse.

Semantic fields model this contrast by collecting large groups of words into separate categories. They might then ask whether unincluded words are semantically close to these word-collectives. But as we saw from [Experiment 1](#semanticfields), semantic proximity is especially tricky when we're talking about *multidimensional* proximity.

A more natively vector-based approach would be to instead model the contrast between abstract and concrete discourse as exactly that, a *contrast*. Contrast can be represented mathematically as subtraction. And subtraction can be performed on vectors to produce yet another vector: *V(Abstract-Concrete) = V(Abstract terms) - V(Concrete terms)*. In natural language, V(Abstract-Concrete) would point *from* the center-of-gravity (i.e. the average) of the vector positions of all the included concrete terms, and *toward* the center-of-gravity of the vector positions of all included abstract terms.

### <i>Theoretical Interlude 1:</i> Vector averages and Lockean abstractions

Two conceptual turns have just happened that I think are especially interesting for the 18C. By constructing a "center of gravity" to the vector positions of all our included abstract terms, we produce a new vector, V(Abstract terms)—new, in the sense that it's mathematically independent from all of its included word vectors. I would argue that this new *vector*, V(Abstract terms), models a new *concept* that we might call Abstractness.

[The previous section on "the concept of the concept"](#conceptconcept) has more of the argument for why a vector operation can be said to create or refer to a new and independent concept. But there, the discussed vector operation is subtraction; here, the vector operation is instead an *averaging*, which I think could be said to give mathematical expression to the Lockean approach to abstraction. What the vector operation of averaging does is construct an unreal point, a "virtual focus" (to use a term from 18C optics), located at the multidimensional center of the included terms. This point represents the words' greatest commonality when all their idiosyncratic differences have been averaged away. Now compare this mathematical expression with Locke's own description of the process of abstraction: <blockquote>Of the complex <i>Ideas</i>, signified by the names <i>Man</i>, and <i>Horse</i>, leaving out but those particulars in which they differ, and retaining only those in which they agree, and of those, making a new distinct complex <i>Idea</i>, and giving the name <i>Animal</i> to it, one has a more general term, that comprehends, with Man, several other Creatures (<i>An Essay Concerning Human Understanding</i> [1689], Chapter III, "Of General Terms").</blockquote> The accuracy with which Locke might be describing, in addition to the *mental* operation of abstraction, the *vector* operation of averaging individual word vectors to produce "a new distinct complex *Idea*", is striking.

### <i>Theoretical Interlude 2:</i> Vector subtractions and spectral concepts

The second operation involved in producing *V(Abstact-Concrete) = V(Abstract)-V(Concrete)*, beyond the operation of averaging all the abstract word vectors to produce V(Abstract), is the subtraction between the two virtual focal points that result from that averaging. [See [this section](#closereading) for a close reading of how subtraction, contrast, and analogies may be conceptual operations particularly distinctive of 18C discourse.]

But what does the vector V(Abstract-Concrete) mean? What happens when we subtract away the semantic profile of Concreteness from the semantic profile of Abstractness? We are left with something independent of V(Abstract) and V(Concrete). Recall that these latter two vectors represent the concepts that result from the Lockean smoothing of abstract or concrete words down to their greatest common denominator. By contrast, V(Abstract-Concrete) is a vector representing the concept of the *contrast* between V(Abstract) and V(Concrete), Abstractness and Concreteness. In other words, V(Abstract-Concrete) means Abstractness *as contrasted with* Concreteness.

It helps to see how V(Abstract-Concrete) is an independent vector and concept if we think about the conceptual instability of its composite vectors, V(Abstract) and V(Concrete). For instance, if V(Abstract) means the average vector position of all the words in the Abstract Values semantic fields listed in [Experiment 1](#semanticfields), then would the central point of V(Abstract) *necessarily* represent the concept of Abstractness? The fields, after all, were called Abstract *Values* for a reason: they comprise not simply abstractions, but abstractions evaluating and regulating moral, social, affective, and intellectual behavior. V(Abstract) is thus conceptually unstable: does it represent Abstractness, or Abstract-Value-ness?

This is how V(Abstract-Concrete) so clearly represents an altogether distinct concept. By subtracting V(Concrete) from V(Abstract), the resulting vector V(Abstract-Concrete) represents, not *all* of the features of V(Abstract) or V(Concrete), but rather only *the vector along which* the features of V(Abstract) and V(Concrete) differ. That vector, V(Abstract-Concrete), could perhaps more accurately be called Abstractness—but, roughly following [Schmidt's notation](http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html), we can call V(Abstract-Concrete) the concept-vector of *Concreteness <> Abstractness*: that is, the vector, or the *spectrum*, between the two concept-vectors V(Concrete) and V(Abstract).

In a previous section, I suggested that a subtractive vector like V(Abstract-Concrete) might be called a "contrast" vector representing a particular conceptual contrast. But, more speculatively, another name we might give it is a *spectral vector*, representing what might be called a *spectral concept*.

A spectral concept-vector is a *spectrum*: an *axis of difference* along which two concepts are thought most to diverge. This amounts to a quantitative approach to the metaphysics of the binary: in other words, one of the most common, operative, and problematic concepts we have. Gender, for instance, is often problematically *not* thought of as a loose network of conceptual hubs—in mathematical terms, *not* as V(Cis Man) + V(Trans Woman) + V(Genderqueer) + ...—but instead as the spectral concept, V(Man-Woman). Of course, this is how the eighteenth century thought of gender; the vector V(Man-Woman) is thus useful precisely for its articulation of the spectrality of gender in the 18C. But, conversely, that same usefulness applies to our own cultural moment. Just as the vector operations help reveal the operationality always already at work in 18C conceptual discourse, vector operations also help make visible the operationality within our own conceptual discourse—even in our own conceptual frameworks as digital humanists. For these reasons I think vector space semantics can provide a formal language not only for conceptual analysis, but also for conceptual *critique*—as evidenced by Ben Schmidt's recent vector-based work, "[Rejecting the gender binary: a vector-space operation](http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html)" (30 Oct 2015).

A spectral concept-vector is therefore also a *specter*, an unreal conceptual entity which yet nevertheless exists,  making its presence known. The concept is unreal to the extent that, unlike a *word* vector V(X), a spectral vector V(X-Y) *need not have a direct expression in natural language.* And while the same could be said of vector averages like V(Abstract), there is a way in which vector subtraction and spectral vectors like V(Woman-Man) seem to articulate something still more hauntingly *active*, more "virtual" in its 18C sense of an invisible or immaterial *force*. This seems clear enough from the examples above. The received cultural understanding, in the 18C or the 21C, of the semantic *axis of difference* between Woman and Man, expressed as V(Woman-Man), is not only a force, it amounts to oppression. The cultural-semantic force of race, expressed in V(Black-White), has devastated hundreds of millions of lives. These are forces always present, always active—at least latently, virtually. This is why vector subtraction is haunting; and how its irreality is the means, and not the obstacle, to the tragic irony of its reality. A spectrum is, perhaps, by necessity, a specter.

### <i>Experiment 1:</i> Measuring abstractness with V(Abstract-Concrete)

Now that we've unpacked what V(Abstract-Concrete) might mean—the spectrum along which V(Abstract) and V(Concrete) differ, that is, the spectrum of *Concreteness<>Abstractness*—let's do something with V(Abstract-Concrete).

One thing we can do is measure the cosine similarity between any given word vector and our new spectral vector, V(Abstract-Concrete). A word vector might point in roughly the same direction as V(Abstract-Concrete), meaning that it points toward abstractness along the *Concreteness<>Abstractness* vector or spectrum; it might be neutral to the spectrum, pointing *orthogonally* to the V(Abstract-Concrete) vector; or it might point toward concreteness. Cosine similarity measures these possibilities quantitatively, between 1 (pointing toward abstractness), 0 (neutral/orthogonal), and -1 (pointing toward concreteness):

<center><a href="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-1.jpg" target="_blank"><img src="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-1.jpg" width="550" alt="Figure 12: Broken down by part-of-speech, words arranged by Concreteness--Abstractness (X-axis), and the logarithm of their count in ECCO-TCP (Y-axis). Showing the 1,000 most frequent words (MFW)." /></a></center>
*<small>Figure 12: Broken down by part-of-speech, words arranged by Concreteness <> Abstractness (X-axis), and the logarithm of their count in ECCO-TCP (Y-axis). Showing the 1,000 most frequent words (MFW). <a href="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-1b.jpg" target="_blank">See version with 10,000 MFW here</a>.</small>*

Did it work? That is, do we ourselves find the vector V(Abstract-Concrete) to reflect (an 18C conceptualization of) *Concreteness <> Abstractness*? Personally, I do. In each part of speech category the difference is marked: worthy, generous, civil *vs.* red, dark, large; justly, surely, highly *vs.* round, fast, away; nature, degree, wisdom *vs.* bed, door, ground; affected, requires, known *vs.* set, gone, bring. The fact that there are many more abstract than concrete adjectives, and many more concrete than abstract verbs, is also interesting. It may be simply an artifact of the words used to compose V(Abstract) and V(Concrete)—those in the semantic fields outlined in [Experiment 1](#semanticfields)—but it may also reflect real differences in either the English language or 18C usage.

But how good of a measure of abstraction is this? One way to approach this question would be to compare it to existing measures of abstraction. In their paper, "[Concreteness ratings for 40 thousand generally known English word lemmas](http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf)", authors Brysbaert, Warriner, and Kuperman detail their experiment asking, via Mechanical Turk, 4,000 human subjects to rate the relative concreteness of a wide range of English words with which the subjects were familiar. Taking the data made public in the Brysbaert et al study, we can plot, along the two different measures of abstraction, the 1,000 most frequent words in ECCO-TCP that are also in the study's data:

<center><a href="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-2.jpg" target="_blank"><img src="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-2.jpg" width="550" alt="Figure 13: Words arranged by their mean concreteness score, according to the Brysbaert et al. study, along the X-axis; and by their score along the Concreteness--Abstractness spectral vector. Showing the 1,000 most frequent words (MFW). Linear regression significant with an R^2 of 0.31 (1,000 MFW) and 0.40 (10,000 MFW)." /></a></center>
*<small>Figure 13: Words arranged by their mean concreteness score, according to the Brysbaert et al. study, along the X-axis; and by their score along the Concreteness<>Abstractness spectral vector, V(Abstract-Concrete), along the Y-axis. Showing the 1,000 most frequent words (MFW). Linear regression significant with an R^2 of 0.31 (1,000 MFW) and 0.40 (10,000 MFW). <a href="http://ryanheuser.org/wp-content/uploads/2016/04/fig-abstract-2b.jpg" target="_blank">See version with 10,000 MFW here</a>.</small>*

As we would expect, we find some degree of correlation. The trendline is statistically significant, and "explains" about 31% of the variation in the data. But what about that other 69%?

The words above the trendline are more abstract for the 18C than we would expect from 21C study participants; and words below the trendline are more abstract for the 21C than we would expect from the 18C. These "outlier" words are, as in many models, more revealing than those along the central tendency of the trendline. The paradigmatic example of the graph, for me, is "human": for the 21C study participants, "human" is not at all an abstraction, with a concreteness score just shy of the maximum of 5. "Human" is concrete: a human, this human, that human. But for the 18C, of course, "human" operated as one of the largest and most sacred abstractions around: as in "human nature" or the traditional contrast between the human and the divine. Conversely, differences in 18C and 21C semantics also seem to explain some of the words more abstract for the 21C than they were for the 18C: such as "discovered", which for the 21C may have more of a connotation of *mental* discovery, of revealing something to oneself; while in the 18C, its older senses of revealing something to other people may be more dominant. But I'll save further reflections on these results for the [discussion section](#abs-discussion).

<span class="collapseomatic colomat-close scroll-to-trigger" id="measuring">&nbsp;</span>
[/expandsub1]
